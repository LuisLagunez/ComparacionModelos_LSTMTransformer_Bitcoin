{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXGU633EfNKR",
        "outputId": "f06076e6-8643-47b3-fcab-856b0a093617"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# BLOQUE 1 — Descarga y preparación de datos\n",
        "# ============================\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ============================\n",
        "# Caso 1 — Año 2024 (3 trimestres entrenamiento, 1 mes prueba)\n",
        "# ============================\n",
        "\n",
        "fecha_inicial_2024 = pd.Timestamp('2024-01-01')\n",
        "fecha_final_2024   = pd.Timestamp('2024-12-31')\n",
        "\n",
        "# Entrenamiento: 1 enero → 30 septiembre\n",
        "fecha_fin_entrenamiento_2024 = pd.Timestamp('2024-09-30')\n",
        "\n",
        "# Prueba: 1 octubre → 31 diciembre\n",
        "fecha_inicio_prueba_2024     = pd.Timestamp('2024-10-01')\n",
        "\n",
        "# Descarga de datos diarios (solo año 2024)\n",
        "datos_2024 = yf.download(\n",
        "    tickers='BTC-USD',\n",
        "    start=fecha_inicial_2024.strftime('%Y-%m-%d'),\n",
        "    end=fecha_final_2024.strftime('%Y-%m-%d'),\n",
        "    interval='1d',\n",
        "    auto_adjust=False\n",
        ")\n",
        "\n",
        "# Limpieza\n",
        "datos_2024 = datos_2024.reset_index()\n",
        "datos_2024 = datos_2024.rename(columns=str)\n",
        "datos_2024 = datos_2024[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "datos_2024['Date'] = pd.to_datetime(datos_2024['Date'])\n",
        "datos_2024 = datos_2024.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Etiquetas para el split\n",
        "datos_2024['Split'] = np.where(\n",
        "    datos_2024['Date'] <= fecha_fin_entrenamiento_2024,\n",
        "    'train_2024_9m',\n",
        "    'test_2024_3m'\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# Caso 2 — Desde 2010 hasta final de 2024\n",
        "# ============================\n",
        "\n",
        "fecha_inicio_hist = pd.Timestamp('2010-07-01')\n",
        "fecha_fin_hist    = pd.Timestamp('2024-12-31')\n",
        "\n",
        "# Descarga\n",
        "datos_total = yf.download(\n",
        "    tickers='BTC-USD',\n",
        "    start=fecha_inicio_hist.strftime('%Y-%m-%d'),\n",
        "    end=fecha_fin_hist.strftime('%Y-%m-%d'),\n",
        "    interval='1d',\n",
        "    auto_adjust=False\n",
        ")\n",
        "\n",
        "# Limpieza\n",
        "datos_total = datos_total.reset_index()\n",
        "datos_total = datos_total.rename(columns=str)\n",
        "datos_total = datos_total[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "datos_total['Date'] = pd.to_datetime(datos_total['Date'])\n",
        "datos_total = datos_total.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# División: historial completo para entrenar, 2024 para prueba\n",
        "fecha_inicio_test_hist = pd.Timestamp('2024-01-01')\n",
        "\n",
        "datos_total['Split'] = np.where(\n",
        "    datos_total['Date'] < fecha_inicio_test_hist,\n",
        "    'train_full_history_until_2023',\n",
        "    'test_2024_full_history'\n",
        ")\n",
        "\n",
        "# Guardado\n",
        "datos_total.to_csv(\"BTC_2010_2024_Yahoo_Limpio.csv\", index=False)\n",
        "\n",
        "# ============================\n",
        "# Resumen visual\n",
        "# ============================\n",
        "\n",
        "print(\"========================================\")\n",
        "print(\"RESUMEN — Caso 1: Año 2024\")\n",
        "print(\"========================================\")\n",
        "print(datos_2024.head(3))\n",
        "print(datos_2024.tail(3))\n",
        "print(f\"Rango total: {datos_2024['Date'].min().date()} -> {datos_2024['Date'].max().date()}\")\n",
        "print(f\"Entrenamiento (9 meses): {len(datos_2024[datos_2024['Split']=='train_2024_9m'])} filas\")\n",
        "print(f\"Prueba (3 meses): {len(datos_2024[datos_2024['Split']=='test_2024_3m'])} filas\\n\")\n",
        "\n",
        "print(\"===========================================\")\n",
        "print(\"RESUMEN — Caso 2: Historia completa → Test en 2024\")\n",
        "print(\"===========================================\")\n",
        "print(datos_total.head(3))\n",
        "print(datos_total.tail(3))\n",
        "print(f\"Entrenamiento: 2010 → 2023 | Filas: {len(datos_total[datos_total['Split']=='train_full_history_until_2023'])}\")\n",
        "print(f\"Prueba: 2024 | Filas: {len(datos_total[datos_total['Split']=='test_2024_full_history'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph_Ts1AwjbuN",
        "outputId": "84e8b769-35f0-4d27-ab29-1276ef71595e"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# BLOQUE 2 — Escalado, secuencias y utilidades Walk-Forward\n",
        "# ============================\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ---------------------------------------\n",
        "# Ventana e horizontes\n",
        "# ---------------------------------------\n",
        "\n",
        "WINDOW = 60\n",
        "H_SEMANAL = 7\n",
        "H_MENSUAL = 30\n",
        "\n",
        "# ---------------------------------------\n",
        "# Preparar arrays multivariados y fechas\n",
        "# ---------------------------------------\n",
        "\n",
        "cols_features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "\n",
        "data_2024_raw = datos_2024[cols_features].values.astype(float)\n",
        "dates_2024 = datos_2024['Date'].values\n",
        "\n",
        "data_total_raw = datos_total[cols_features].values.astype(float)\n",
        "dates_total = datos_total['Date'].values\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# Función para crear secuencias\n",
        "# ---------------------------------------\n",
        "\n",
        "def crear_secuencias_multivariadas(data_scaled, window, horizon, target_col=3):\n",
        "    X, y = [], []\n",
        "    n = len(data_scaled)\n",
        "    for i in range(n - window - horizon + 1):\n",
        "        X.append(data_scaled[i : i + window, :])\n",
        "        y.append(data_scaled[i + window + horizon - 1, target_col])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y).reshape(-1, 1)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# Escaladores independientes\n",
        "# ---------------------------------------\n",
        "\n",
        "def scale_using_train_only(data_raw, dates, train_end_date):\n",
        "    mask_train_rows = dates <= np.datetime64(train_end_date)\n",
        "    train_cut_idx = np.where(mask_train_rows)[0].max()\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(data_raw[: train_cut_idx + 1, :])  # Fit solo en entrenamiento\n",
        "    data_scaled = scaler.transform(data_raw)\n",
        "\n",
        "    return scaler, data_scaled, train_cut_idx\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# Definición del Walk-Forward\n",
        "# ======================================================\n",
        "\n",
        "def walk_forward_generator(X_all, y_all, fechas_objetivo, mask_test_seq):\n",
        "    test_indices = np.where(mask_test_seq)[0]\n",
        "    for idx in test_indices:\n",
        "\n",
        "        if idx == 0:\n",
        "            X_train_cur = np.zeros((0, X_all.shape[1], X_all.shape[2]), dtype=X_all.dtype)\n",
        "            y_train_cur = np.zeros((0, 1), dtype=y_all.dtype)\n",
        "        else:\n",
        "            X_train_cur = X_all[:idx]\n",
        "            y_train_cur = y_all[:idx]\n",
        "\n",
        "        X_pred = X_all[idx:idx+1]\n",
        "        y_true = y_all[idx]\n",
        "        fecha_obj = fechas_objetivo[idx]\n",
        "\n",
        "        yield X_train_cur, y_train_cur, X_pred, y_true, fecha_obj, idx\n",
        "\n",
        "# ---------------------------------------\n",
        "# CASO 1: 2024\n",
        "# ---------------------------------------\n",
        "\n",
        "scaler_2024, serie_2024_scaled, train_cut_idx_2024 = scale_using_train_only(\n",
        "    data_2024_raw, dates_2024, fecha_fin_entrenamiento_2024\n",
        ")\n",
        "\n",
        "X_2024, y_2024 = crear_secuencias_multivariadas(\n",
        "    serie_2024_scaled, WINDOW, H_SEMANAL, target_col=3\n",
        ")\n",
        "\n",
        "fechas_objetivo_2024 = dates_2024[WINDOW + H_SEMANAL - 1 : ]\n",
        "\n",
        "mask_train_seq_2024 = fechas_objetivo_2024 <= np.datetime64(fecha_fin_entrenamiento_2024)\n",
        "mask_test_seq_2024  = fechas_objetivo_2024 >= np.datetime64(fecha_inicio_prueba_2024)\n",
        "\n",
        "X_train_2024 = X_2024[mask_train_seq_2024]\n",
        "y_train_2024 = y_2024[mask_train_seq_2024]\n",
        "X_test_2024  = X_2024[mask_test_seq_2024]\n",
        "y_test_2024  = y_2024[mask_test_seq_2024]\n",
        "\n",
        "# Crear Walk-Forward\n",
        "walk_2024 = list(walk_forward_generator(\n",
        "    X_2024, y_2024, fechas_objetivo_2024, mask_test_seq_2024\n",
        "))\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# CASO 2: Histórico\n",
        "# ---------------------------------------\n",
        "\n",
        "scaler_total, serie_total_scaled, train_cut_idx_total = scale_using_train_only(\n",
        "    data_total_raw, dates_total, fecha_inicio_test_hist - np.timedelta64(1, 'D')\n",
        ")\n",
        "\n",
        "X_total, y_total = crear_secuencias_multivariadas(\n",
        "    serie_total_scaled, WINDOW, H_MENSUAL, target_col=3\n",
        ")\n",
        "\n",
        "fechas_objetivo_total = dates_total[WINDOW + H_MENSUAL - 1 : ]\n",
        "\n",
        "mask_test_seq_total = fechas_objetivo_total >= np.datetime64(fecha_inicio_test_hist)\n",
        "\n",
        "X_train_total = X_total[~mask_test_seq_total]\n",
        "y_train_total = y_total[~mask_test_seq_total]\n",
        "X_test_total  = X_total[mask_test_seq_total]\n",
        "y_test_total  = y_total[mask_test_seq_total]\n",
        "\n",
        "# Crear Walk-Forward\n",
        "walk_total = list(walk_forward_generator(\n",
        "    X_total, y_total, fechas_objetivo_total, mask_test_seq_total\n",
        "))\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# Resumen shapes\n",
        "# ---------------------------------------\n",
        "\n",
        "def resumen_shapes():\n",
        "    print(\"=== RESUMEN SECUENCIAS ===\")\n",
        "    print(\"-- 2024 --\")\n",
        "    print(\"Raw rows:\", data_2024_raw.shape[0], \" -> sequences:\", X_2024.shape[0])\n",
        "    print(\"Train seqs:\", X_train_2024.shape[0], \" Test seqs:\", X_test_2024.shape[0])\n",
        "    print(\"\")\n",
        "    print(\"-- HISTÓRICO --\")\n",
        "    print(\"Raw rows:\", data_total_raw.shape[0], \" -> sequences:\", X_total.shape[0])\n",
        "    print(\"Train seqs:\", X_train_total.shape[0], \" Test seqs:\", X_test_total.shape[0])\n",
        "    print(\"\")\n",
        "    print(\"Scaler 2024 fitted en filas 0..\", train_cut_idx_2024)\n",
        "    print(\"Scaler total fitted en filas 0..\", train_cut_idx_total)\n",
        "\n",
        "\n",
        "# Ejecutar resumen\n",
        "resumen_shapes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqF0Raewsq84",
        "outputId": "2203528a-182e-48f5-e98b-92fd85e171c4"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# BLOQUE 3 — LSTM Walk-Forward Paralelizado\n",
        "# ============================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DISPOSITIVO ACTIVO:\", device)\n",
        "\n",
        "# ------------------------------\n",
        "# Fijar semillas\n",
        "# ------------------------------\n",
        "\n",
        "def fijar_semillas(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Modelo LSTM\n",
        "# ------------------------------\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=5, hidden_size=64, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                            batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# ENTRENAR UNA SOLA VENTANA\n",
        "# ------------------------------\n",
        "\n",
        "def entrenar_lstm_un_paso(Xtr, ytr, epochs=30, lr=1e-3, batch_size=64):\n",
        "\n",
        "    ds = TensorDataset(\n",
        "        torch.tensor(Xtr, dtype=torch.float32),\n",
        "        torch.tensor(ytr, dtype=torch.float32).view(-1, 1)\n",
        "    )\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = LSTMModel().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Walk-Forward\n",
        "# ------------------------------\n",
        "\n",
        "def predecir_walk_forward_lstm(generator, repeticiones=1, epochs=30, lr=1e-3):\n",
        "\n",
        "    predicciones = []\n",
        "\n",
        "    for (Xtr, ytr, Xfuture, ytrue, fecha_objetivo, idx) in tqdm(generator,\n",
        "                                                               desc=\"Walk-Forward LSTM (rápido)\"):\n",
        "\n",
        "        preds_rep = []\n",
        "\n",
        "        for r in range(repeticiones):\n",
        "            fijar_semillas(100 + r)\n",
        "\n",
        "            model = entrenar_lstm_un_paso(Xtr, ytr,\n",
        "                                          epochs=epochs,\n",
        "                                          lr=lr,\n",
        "                                          batch_size=64)  # <<< más rápido\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            Xf = torch.tensor(Xfuture, dtype=torch.float32).to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(Xf).cpu().numpy().flatten()[0]\n",
        "\n",
        "            preds_rep.append(pred)\n",
        "\n",
        "        predicciones.append({\n",
        "            \"fecha\": fecha_objetivo,\n",
        "            \"pred\": np.mean(preds_rep),\n",
        "            \"pred_std\": np.std(preds_rep),\n",
        "            \"index\": idx\n",
        "        })\n",
        "\n",
        "    return predicciones\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# EJECUCIÓN\n",
        "# ------------------------------\n",
        "\n",
        "print(\"\\nEjecutando LSTM con Walk-Forward (rápido)...\")\n",
        "\n",
        "preds_walk_2024 = predecir_walk_forward_lstm(\n",
        "    walk_2024, repeticiones=5, epochs=16, lr=1e-3\n",
        ")\n",
        "\n",
        "preds_walk_total = predecir_walk_forward_lstm(\n",
        "    walk_total, repeticiones=5, epochs=16, lr=1e-3\n",
        "  )\n",
        "print(\"LSTM con Walk-Forward completado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT_lbkQk5u8C",
        "outputId": "ecc58222-2f40-4fb3-ccea-8e03da9e2ade"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# BLOQUE 4 — Transformer Walk-Forward Paralelizado\n",
        "# ============================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "# ------------------------------\n",
        "# Dispositivo\n",
        "# ------------------------------\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DISPOSITIVO ACTIVO:\", device)\n",
        "\n",
        "# ------------------------------\n",
        "# Fijar semillas\n",
        "# ------------------------------\n",
        "\n",
        "def fijar_semillas(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True      # <--- aceleración\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Positional Encoding\n",
        "# ------------------------------\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1), :]\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Modelo Transformer\n",
        "# ------------------------------\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, seq_len=60, d_model=64, nhead=4,\n",
        "                 num_layers=2, dim_feedforward=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_proj = nn.Linear(5, d_model)\n",
        "        self.positional = PositionalEncoding(d_model, max_len=seq_len)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "            activation=\"gelu\"\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.head = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x) + self.positional(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.norm(x)\n",
        "        return self.head(x[:, -1, :])\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# ENTRENAR UNA VENTANA\n",
        "# ------------------------------\n",
        "\n",
        "def entrenar_transformer_un_paso(X_train, y_train,\n",
        "                                 epochs=40, lr=1e-4, batch_size=64):\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    ds = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = TransformerModel().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# WALK-FORWARD\n",
        "# ------------------------------\n",
        "\n",
        "def predecir_walk_forward_transformer(generator,\n",
        "                                      repeticiones=1, epochs=40, lr=1e-4):\n",
        "\n",
        "    predicciones = []\n",
        "\n",
        "    for (Xtr, ytr, Xfuture, ytrue, fecha_objetivo, idx) in tqdm(generator,\n",
        "                                                                desc=\"Walk-Forward Transformer (rápido)\"):\n",
        "\n",
        "        preds_rep = []\n",
        "        Xfuture_tensor = torch.tensor(Xfuture, dtype=torch.float32).to(device)\n",
        "\n",
        "        for r in range(repeticiones):\n",
        "            fijar_semillas(300 + r)\n",
        "\n",
        "            model = entrenar_transformer_un_paso(\n",
        "                Xtr, ytr, epochs=epochs, lr=lr, batch_size=64  # <--- más rápido\n",
        "            )\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred = model(Xfuture_tensor).cpu().numpy().flatten()[0]\n",
        "                preds_rep.append(pred)\n",
        "\n",
        "        predicciones.append({\n",
        "            \"fecha\": fecha_objetivo,\n",
        "            \"pred\": np.mean(preds_rep),\n",
        "            \"pred_std\": np.std(preds_rep),\n",
        "            \"index\": idx\n",
        "        })\n",
        "\n",
        "    return predicciones\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# EJECUCIÓN\n",
        "# ------------------------------\n",
        "\n",
        "print(\"\\nEjecutando Transformer con Walk-Forward...\")\n",
        "\n",
        "preds_walk_2024_tf = predecir_walk_forward_transformer(\n",
        "    walk_2024, repeticiones=5, epochs=16, lr=1e-4\n",
        ")\n",
        "\n",
        "preds_walk_total_tf = predecir_walk_forward_transformer(\n",
        "    walk_total, repeticiones=5, epochs=16, lr=1e-4\n",
        ")\n",
        "\n",
        "print(\"Transformer con Walk-Forward completado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P8cbUIc7Dy_T",
        "outputId": "0ced7edd-d072-4d6a-85d5-1ab0a78637a7"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# BLOQUE 5 — Evaluación y visualización\n",
        "# ============================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "\n",
        "EPS = 1e-8\n",
        "\n",
        "# ------------------------------\n",
        "# Utilidades\n",
        "# ------------------------------\n",
        "\n",
        "def ensure_1d(arr):\n",
        "    a = np.asarray(arr)\n",
        "    if a.ndim == 2 and a.shape[1] == 1:\n",
        "        return a.ravel()\n",
        "    return a.reshape(-1)\n",
        "\n",
        "def desescalar(scaler, arr_scaled):\n",
        "    a = np.asarray(arr_scaled).reshape(-1, 1)\n",
        "    dummy = np.zeros((len(a), 5))\n",
        "    dummy[:, 3] = a[:, 0]  # 3 = columna CLOSE dentro del MinMax multivariante\n",
        "    return scaler.inverse_transform(dummy)[:, 3]\n",
        "\n",
        "def align_lengths(y, *preds):\n",
        "    \"\"\"\n",
        "    Recorta todos los arrays al largo mínimo (usualmente usar y como referencia)\n",
        "    Retorna (y_trim, pred1_trim, pred2_trim, ...)\n",
        "    \"\"\"\n",
        "    L = min(len(y), *(len(p) for p in preds))\n",
        "    y_t = np.asarray(y)[:L]\n",
        "    preds_t = [np.asarray(p)[:L] for p in preds]\n",
        "    return (y_t, *preds_t)\n",
        "\n",
        "# ------------------------------\n",
        "# Extraer predicciones de los walks (listas de dicts)\n",
        "# ------------------------------\n",
        "\n",
        "preds_2024 = np.array([p[\"pred\"] for p in preds_walk_2024])\n",
        "preds_2024_tf = np.array([p[\"pred\"] for p in preds_walk_2024_tf])\n",
        "\n",
        "preds_total = np.array([p[\"pred\"] for p in preds_walk_total])\n",
        "preds_total_tf = np.array([p[\"pred\"] for p in preds_walk_total_tf])\n",
        "\n",
        "# Asegurar forma correcta (provenientes de Bloque 2)\n",
        "y_test_2024 = ensure_1d(y_test_2024)\n",
        "y_test_total = ensure_1d(y_test_total)\n",
        "\n",
        "# ------------------------------\n",
        "# Desescalar (usar scalers de Bloque 2)\n",
        "# ------------------------------\n",
        "\n",
        "y_test_2024_real   = desescalar(scaler_2024, y_test_2024)\n",
        "preds_2024_real    = desescalar(scaler_2024, preds_2024)\n",
        "preds_2024_tf_real = desescalar(scaler_2024, preds_2024_tf)\n",
        "\n",
        "y_test_total_real   = desescalar(scaler_total, y_test_total)\n",
        "preds_total_real    = desescalar(scaler_total, preds_total)\n",
        "preds_total_tf_real = desescalar(scaler_total, preds_total_tf)\n",
        "\n",
        "# ------------------------------\n",
        "# Alinear longitudes por seguridad\n",
        "# ------------------------------\n",
        "\n",
        "y_test_2024_real, preds_2024_real, preds_2024_tf_real = align_lengths(\n",
        "    y_test_2024_real, preds_2024_real, preds_2024_tf_real\n",
        ")\n",
        "\n",
        "y_test_total_real, preds_total_real, preds_total_tf_real = align_lengths(\n",
        "    y_test_total_real, preds_total_real, preds_total_tf_real\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# Métricas de evaluación\n",
        "# ------------------------------\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), EPS, None))) * 100\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    return np.mean(2 * np.abs(y_true - y_pred) /\n",
        "                   (np.abs(y_true) + np.abs(y_pred) + EPS)) * 100\n",
        "\n",
        "def precision_promedio(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    return 100 * (1 - mae / (np.mean(y_true) + EPS))\n",
        "\n",
        "def precision_punto_a_punto(y_true, y_pred):\n",
        "    return np.mean(100 * (1 - np.abs(y_true - y_pred) / (np.abs(y_true) + EPS)))\n",
        "\n",
        "def directional_accuracy(y_true, y_pred):\n",
        "    if len(y_true) < 2 or len(y_pred) < 2:\n",
        "        return np.nan\n",
        "    return np.mean(np.sign(np.diff(y_true)) == np.sign(np.diff(y_pred))) * 100\n",
        "\n",
        "def pearson_safe(y_true, y_pred):\n",
        "    try:\n",
        "        if len(y_true) < 2 or len(y_pred) < 2:\n",
        "            return np.nan\n",
        "        return pearsonr(y_true, y_pred)[0]\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def resumen_metrics(y_true, y_pred, nombre):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r = rmse(y_true, y_pred)\n",
        "    m = mape(y_true, y_pred)\n",
        "    s = smape(y_true, y_pred)\n",
        "    p = precision_promedio(y_true, y_pred)\n",
        "    p2 = precision_punto_a_punto(y_true, y_pred)\n",
        "    da = directional_accuracy(y_true, y_pred)\n",
        "    corr = pearson_safe(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n=== {nombre} ===\")\n",
        "    print(f\"MAE: {mae:.2f} USD\")\n",
        "    print(f\"RMSE: {r:.2f} USD\")\n",
        "    print(f\"MAPE: {m:.2f}%\")\n",
        "    print(f\"sMAPE: {s:.2f}%\")\n",
        "    print(f\"Precisión promedio: {p:.2f}%\")\n",
        "    print(f\"Precisión punto a punto (media %): {p2:.2f}%\")\n",
        "    print(f\"Directional Accuracy: {da if not np.isnan(da) else 'NA'}%\")\n",
        "    print(f\"Correlación Pearson: {corr if not np.isnan(corr) else 'NA'}\")\n",
        "    return {\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": r,\n",
        "        \"MAPE(%)\": m,\n",
        "        \"sMAPE(%)\": s,\n",
        "        \"Prec.(%)\": p,\n",
        "        \"Prec Punto a Punto(%)\": p2,\n",
        "        \"Directional Acc.(%)\": da,\n",
        "        \"Pearson\": corr\n",
        "    }\n",
        "\n",
        "# ------------------------------\n",
        "# Ejecutar métricas\n",
        "# ------------------------------\n",
        "\n",
        "print(\"\\n=== METRICAS — CASO 2024 (Promedio 7 días) ===\")\n",
        "met_lstm_2024 = resumen_metrics(y_test_2024_real, preds_2024_real, \"LSTM 2024\")\n",
        "met_tf_2024 = resumen_metrics(y_test_2024_real, preds_2024_tf_real, \"Transformer 2024\")\n",
        "\n",
        "print(\"\\n=== METRICAS — CASO HISTÓRICO (Promedio 30 días) ===\")\n",
        "met_lstm_total = resumen_metrics(y_test_total_real, preds_total_real, \"LSTM Histórico\")\n",
        "met_tf_total = resumen_metrics(y_test_total_real, preds_total_tf_real, \"Transformer Histórico\")\n",
        "\n",
        "# ------------------------------\n",
        "# Crear tabla consolidada y guardado\n",
        "# ------------------------------\n",
        "\n",
        "metrics_df = pd.DataFrame([\n",
        "    {\"Modelo\": \"LSTM 2024 (7 días)\", **met_lstm_2024},\n",
        "    {\"Modelo\": \"Transformer 2024 (7 días)\", **met_tf_2024},\n",
        "    {\"Modelo\": \"LSTM Histórico (30 días)\", **met_lstm_total},\n",
        "    {\"Modelo\": \"Transformer Histórico (30 días)\", **met_tf_total},\n",
        "])\n",
        "\n",
        "print(\"\\n=== TABLA DE MÉTRICAS COMPLETAS ===\\n\")\n",
        "print(metrics_df)\n",
        "metrics_df.to_csv(\"metrics_resultados_completos.csv\", index=False)\n",
        "print(\"\\nArchivo 'metrics_resultados_completos.csv' guardado.\")\n",
        "\n",
        "# ------------------------------\n",
        "# Fechas reales para eje X (desde Bloque 1)\n",
        "# ------------------------------\n",
        "\n",
        "fechas_test_2024 = datos_2024[datos_2024[\"Split\"] == \"test_2024_3m\"][\"Date\"].values\n",
        "fechas_test_total = datos_total[datos_total[\"Split\"] == \"test_2024_full_history\"][\"Date\"].values\n",
        "\n",
        "# Alinear fechas con los arrays (recortar al mismo tamaño)\n",
        "def align_dates_with_series(dates, series_len):\n",
        "    dates = np.asarray(dates)\n",
        "    if len(dates) > series_len:\n",
        "        return dates[-series_len:]\n",
        "    return dates\n",
        "\n",
        "fechas_test_2024 = align_dates_with_series(fechas_test_2024, len(y_test_2024_real))\n",
        "fechas_test_total = align_dates_with_series(fechas_test_total, len(y_test_total_real))\n",
        "\n",
        "# ------------------------------\n",
        "# Plots\n",
        "# ------------------------------\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
        "\n",
        "def plot_series_dates(fechas, y_real, y_lstm, y_tf=None, title=\"\"):\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(fechas, y_real, label=\"Real\", linewidth=2, color=\"black\")\n",
        "    plt.plot(fechas, y_lstm, label=\"LSTM\", linewidth=2)\n",
        "    if y_tf is not None:\n",
        "        plt.plot(fechas, y_tf, label=\"Transformer\", linewidth=2)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Fecha\")\n",
        "    plt.ylabel(\"Precio (USD)\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_error_dates(fechas, error_lstm, error_tf=None, title=\"\"):\n",
        "    plt.figure(figsize=(14,4))\n",
        "    plt.plot(fechas, error_lstm, label=\"Error LSTM\")\n",
        "    if error_tf is not None:\n",
        "        plt.plot(fechas, error_tf, label=\"Error Transformer\")\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Fecha\")\n",
        "    plt.ylabel(\"Error absoluto (USD)\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# CASO 2024\n",
        "plot_series_dates(\n",
        "    fechas_test_2024,\n",
        "    y_test_2024_real,\n",
        "    preds_2024_real,\n",
        "    preds_2024_tf_real,\n",
        "    title=\"Predicción semanal (H=7) — Año 2024\"\n",
        ")\n",
        "\n",
        "err_lstm_2024 = np.abs(y_test_2024_real - preds_2024_real)\n",
        "err_tf_2024 = np.abs(y_test_2024_real - preds_2024_tf_real)\n",
        "\n",
        "plot_error_dates(\n",
        "    fechas_test_2024,\n",
        "    err_lstm_2024,\n",
        "    err_tf_2024,\n",
        "    title=\"Error absoluto — Predicción semanal 2024\"\n",
        ")\n",
        "\n",
        "# CASO HISTÓRICO\n",
        "plot_series_dates(\n",
        "    fechas_test_total,\n",
        "    y_test_total_real,\n",
        "    preds_total_real,\n",
        "    preds_total_tf_real,\n",
        "    title=\"Predicción mensual (H=30) — Histórico (2010–2024)\"\n",
        ")\n",
        "\n",
        "err_lstm_total = np.abs(y_test_total_real - preds_total_real)\n",
        "err_tf_total = np.abs(y_test_total_real - preds_total_tf_real)\n",
        "\n",
        "plot_error_dates(\n",
        "    fechas_test_total,\n",
        "    err_lstm_total,\n",
        "    err_tf_total,\n",
        "    title=\"Error absoluto — Predicción mensual Histórico\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
